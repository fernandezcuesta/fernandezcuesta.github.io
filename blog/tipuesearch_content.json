{"pages":[{"text":"GUI tool for SELinux: system-config-selinux Files, folders, devices → SELinux objects Processes → SELinux subjects → Both mapped in SELinux contexts Processes are confined in their contexts. Contexts define which files a process can access and which other processes can interact with. Configuration file: /etc/sysconfig/selinux # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - SELinux is fully disabled. SELINUX = enforcing # SELINUXTYPE= type of policy in use. Possible values are: # targeted - Only targeted network daemons are protected. # strict - Full SELinux protection. SELINUXTYPE = targeted Check current mode: # sestatus SELinux status: enabled SELinuxfs mount: /selinux Current mode: permissive Mode from config file: permissive Policy version: 24 Policy from config file: targeted # getenforce Enforcing Change the current mode: # setenforce [ Enforcing | Permissive | 1 | 0 ] USERS Linux users are mapped into SELinux users (by default Linux users are unconfined). To show the mapping, run: # semanage login -l Login Name SELinux User MLS/MCS Range Service __default__ unconfined_u s0-s0:c0.c1023 * root unconfined_u s0-s0:c0.c1023 * system_u system_u s0-s0:c0.c1023 * Show SELinux confined users parameters: # semanage user -l Set SELinux rules for a specific user: # semanage login -s user_u -a one_user Set confined user as default for every new added accounts: # semanage login -m -S targeted -s \"user_u\" -r s0 __default__ BOOLEANS Show list of booleans with current and default status and short description: # semanage boolean -l # # Only list of booleans with current status # getsebool -a Modify a SELinux boolean: For example, in order to enable samba shares ( -P for permanent): # setsebool -P allow_smbd_anon_write on or # semanage boolean -m --on allow_smbd_anon_write CONTEXTS SELinux contexts for processes: # ps -eZfx SELinux contexts for users: # id -Z SELinux contexts for files: # ls -lZ Change SELinux file contexts Temporary changes : chcon # chcon --reference /var/ftp /ftp # chcon -R -u system_u -t public_content_rw_t /ftp Where, as an example: public_content_rw_t allows uploads to an FTP folder Permanent changes : semanage fcontext # #Adds a new record to the file contexts, but does not apply changes # semanage fcontext -a -t public_content_rw_t \"/ftp(/.*)?\" # #Restore contexts according to records, thus applying changes # restorecon -Rv /ftp # ls -ldZ /ftp Unconfined processes: # ls -Z /usr/sbin/httpd -rwxr-xr-x root root system_u:object_r:httpd_exec_t:s0 /usr/sbin/httpd # chcon -t bin_t /usr/sbin/httpd # ls -Z /usr/sbin/httpd -rwxr-xr-x. root root system_u:object_r:bin_t:s0 /usr/sbin/httpd Show all available SELinux contexts # seinfo -t # seinfo -t | grep '&#94;\\s*ftp' Restore SELinux contexts Show default file contexts: # semanage fcontext -l # restorecon -v -F -R /home/user/ftp default file contexts are defined in /etc/selinux/contexts/files/file_contexts Only show default SELinux context for a specific folder/file # matchpathcon /var/www/html FILES Mount filesystem with specific context # mount -o context = \"system_u:object_r:httpd_sys_content_t:s0\" server:/export /var/www/html/content Options: -o context : usually for removable media from non-SELinux systems (i.e. a FAT32 formatted USB drive) -o fscontext : set or override the filesystem object instance security context (i.e. set ext3 filesystem security) -o defcontext : set or override the default file security context (instead of default_t ) If the same directory of an export has to be mounted with diferent contexts, use -o nosharecache option. Archiving files with extended attributes # tar --selinux If extracting a tar file without extended attribute information, do: # tar -zxvf archive.tar.gz | restorecon -f - OTHER Copy files while preserving the context information $ cp --preserve = context source_file destination_file Add a custom port for a service # semanage port -a -t http_port_t -p 10443 Mounting filesystems with specific SELinux contexts # mount server:/export /local/mount/point -o context = \"system_u:object_r:httpd_sys_content_t:s0\" or in /etc/fstab # server:/export /local/mount/ nfs context = \"system_u:object_r:httpd_sys_content_t:s0\" 0 0 TROUBLESHOOT # # Search 'qemu' related SELinux violations # ausearch -m avc -c qemu # # Automatically generate a policy # ausearch -m avc -c qemu | audit2allow -M mypol # sealert -a /var/log/audit/audit.log # (TUI) # sealert # (GUI) Troubleshoot a specific problem Reproduce the problem while watching the logs: # tail -f /var/log/audit/audit.log | audit2why or # tail -f /var/log/audit/audit.log | audit2allow -a In addition, as explained in certdepot , we can filter on the AVC as follows: # tailf /var/log/audit/audit.log ... type=AVC msg=audit(1415714880.156:29): avc: denied { name_connect } for pid=1349 \\ comm=\"nginx\" dest=8080 scontext=unconfined_u:system_r:httpd_t:s0 \\ tcontext=system_u:object_r:http_cache_port_t:s0 tclass=tcp_socket # grep 1415714880.156:29 /var/log/audit/audit.log | audit2why If an output like this one is shown: #============= httpd_sys_script_t ============== allow httpd_sys_script_t self:capability { setuid setgid }; allow httpd_sys_script_t self:process setrlimit; proceed with flag -M : # tailf /var/log/audit/audit.log | audit2allow -a -M my_semanage_file And fix with: # semodule -i my_semanage_file.pp This process may be repeated several times to fully troubleshoot the problem. If the setroubleshoot-server is installed, some errors may appear directly in the journal or in /var/log/messages like: SELinux is preventing [...] run sealert -l 21d07129-dd4f-4ac7-9579-fd17e89f53ee References RHEL7 SELinux user's and Administrator's Guide Certdepot","title":"Keep calm and setenforce 1 - SELinux notes","tags":"misc","loc":"http://fernandezcuesta.github.io/keep-calm-and-setenforce-1-selinux-notes.html","url":"http://fernandezcuesta.github.io/keep-calm-and-setenforce-1-selinux-notes.html"},{"text":"Pros: Almost everything: automatization, high paralelysm, lot of customizable elements, … Debug capabilities: defining an environmental variable PACKER_LOG with any value will redirect detailed log information to stderr. Cons (if any): Some elements are't too flexible. For example, with file provisioners we cannot use wildcards, only individual files/directories can be copied to the VMs. Not a big issue that can be circumvented in many ways. If a postprocess error occurs the VM is deleted and the whole process must be repeated from scratch. A nice to have default behaviour would be to allow a resume operation (i.e. OS is installed, some packages were successfully installedbut scripts are missing; resuming would retry from the last stage). Vagrant postprocessor works copies the artifact to /tmp before building the box. While in most cases this is not a problem, I got several no space left errors when working on a system where /tmp is a ramdisk and overall memory usage is high. Although this is clearly a vagrant issue, VM is reloaded (all changes are rolled back to the state where packer's postprocessor finished) if there's a problem with vagrant up . There's no chance for the user to fix the VM before it is reloaded. Packer template The template for packer is a JSON file containing several sections. Main section ( builders ) where the VM is defined. In this case a local ISO and kickstart files are specified and the artifacts (that is, what is produced by packer , is stored in centos7-test folder. Only a builder for QEMU / KVM is set in this example but we could build VMs for Docker, EC2 , VirtualBox, VMWare, etc. provisioners section, where we can define how the VM will be provisioned once the installation of the OS has ended. In other words, what additional software needs to be installed and configured using either Puppet, Chef or any other supported provisioner (see [https://www.packer.io/docs] for more information). post-processors section where we can say what to do with the artifacts. Example: Over all possible scenarios, a Centos7 vagrant box will be installed starting from the minimal ISO . Additional software is provisioned by a shell script. Under the hood autoprovisioning can also be defined straight into the kickstart file as follows, but doing this may be redundant with the provisioner/s. In this case an already existing kickstart file was used. By default users vagrant and ssh have password set to vagrant as described in vagrant's base boxes specification . Read 1st answer in stackoverflow's discussion about vagrant security for further details about well-known passwords. Artifact generated by the build stage (qcow2 hard disk file for KVM ) isn't deleted when the postprocessor has ended (see Cons above). For the kickstart file, optionally generate an encrypted password: python -c 'import crypt; print(crypt.crypt(\"vagrant\"))' packer template { \"builders\" : [ { \"type\" : \"qemu\" , \"iso_url\" : \"http://ftp.udl.es/pub/centos/7.0.1406/isos/x86_64/CentOS-7.0-1406-x86_64-Minimal.iso\" , \"iso_checksum\" : \"e3afe3f1121d69c40cc23f0bafa05e5d\" , \"iso_checksum_type\" : \"md5\" , \"output_directory\" : \"centos7-test\" , \"ssh_wait_timeout\" : \"30s\" , \"shutdown_command\" : \"shutdown -P now\" , \"disk_size\" : 5000 , \"format\" : \"qcow2\" , \"headless\" : false , \"accelerator\" : \"kvm\" , \"http_directory\" : \".\" , \"http_port_min\" : 10082 , \"http_port_max\" : 10089 , \"ssh_host_port_min\" : 2222 , \"ssh_host_port_max\" : 2229 , \"ssh_username\" : \"root\" , \"ssh_password\" : \"vagrant\" , \"ssh_port\" : 22 , \"ssh_wait_timeout\" : \"90m\" , \"vm_name\" : \"centos7\" , \"net_device\" : \"virtio-net\" , \"disk_interface\" : \"virtio\" , \"boot_wait\" : \"5s\" , \"boot_command\" : [ \"<tab> text ks=http://{{ .HTTPIP }}:{{ .HTTPPort }}/centos7-ks.cfg<enter><wait>\" ] } ], \"provisioners\" : [ { \"type\" : \"shell\" , \"script\" : \"script.sh\" , \"execute_command\" : \"echo 'vagrant' | {{ .Vars }} sudo -E -S sh '{{ .Path }}'\" } ], \"post-processors\" : [ { \"type\" : \"vagrant\" , \"compression_level\" : 9 , \"keep_input_artifact\" : true } ] } provisioner shell script 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # Add EPEL repository yum install -y epel-release # Install git and clone remote repositories # Moved this to early stages to avoid nw outage due to reconfigurations yum install -y git git clone https://github.com/robbyrussell/oh-my-zsh.git /usr/share/oh-my-zsh git clone https://github.com/fernandezcuesta/dotfiles.git # Install missing packages yum install -y htop vim nano tmux setroubleshoot-server bash-completion python-psutil zsh yum groupinstall -y \"Basic Web Server\" # Enable serial line output echo \"GRUB_TERMINAL=\\\"console serial\\\"\" >> /etc/default/grub grubby --update-kernel = ALL --args = \"console=ttyS0\" # Add user for vagrant useradd vagrant -G wheel # Put dotfiles in place mv dotfiles/nanorc/* /usr/share/nano/ git clone https://github.com/gmarik/Vundle.vim.git dotfiles/.vim/bundle/Vundle.vim cp -R dotfiles/.vim /root cp -R dotfiles/.vim /home/vagrant mv dotfiles/*.tmux /usr/local/bin for file in dotfiles/.* ; do [[ -f $file ]] && cp $file . && cp $file /home/vagrant ; done chown -R vagrant:vagrant /home/vagrant rm -Rf dotfiles # Set zsh as default shell chsh -s ` which zsh ` chsh -s ` which zsh ` vagrant # Required by vagrant (http://docs.vagrantup.com/v2/boxes/base.html) sed -i 's/&#94;\\(Defaults[[:space:]]\\+requiretty\\)/#&\\t# required by vagrant/' /etc/sudoers sed -i 's/!visiblepw/visiblepw\\t# required by vagrant/' /etc/sudoers sed -i '/#\\+\\s*Same thing without a password/a vagrant ALL=(ALL) NOPASSWD: ALL' /etc/sudoers Kickstart file install cdrom lang en_US.UTF-8 keyboard us network --bootproto = dhcp authconfig --enableshadow --passalgo = sha512 rootpw --iscrypted $6$RTzeoVEVyTLdKaVM$DTxJ /lov4/JUNrTVtJR0IMdnaeg1DYhi9FsnJdeEae32ewZKqKt9L0aHa51HEgsJnL24WVF6DG1gPMCGwrRBU/ firewall --enabled --service = ssh timezone GMT+1 unsupported_hardware bootloader --location = mbr text skipx zerombr clearpart --all --initlabel part /boot --fstype = ext4 --size = 256 part pv.01 --grow --size = 1 volgroup VolGroup --pesize = 4096 pv.01 logvol / --fstype = xfs --name = lv_root --vgname = VolGroup --grow --size = 1024 logvol swap --name = lv_swap --vgname = VolGroup --size = 2048 auth --useshadow --passalgo = sha512 firstboot --disabled reboot %packages --nobase @core openssh-clients sudo # unnecessary firmware -aic94xx-firmware -atmel-firmware -b43-openfwwf -bfa-firmware -ipw2100-firmware -ipw2200-firmware -ivtv-firmware -iwl100-firmware -iwl1000-firmware -iwl3945-firmware -iwl4965-firmware -iwl5000-firmware -iwl5150-firmware -iwl6000-firmware -iwl6000g2a-firmware -iwl6050-firmware -libertas-usb8388-firmware -ql2100-firmware -ql2200-firmware -ql23xx-firmware -ql2400-firmware -ql2500-firmware -rt61pci-firmware -rt73usb-firmware -xorg-x11-drv-ati-firmware -zd1211-firmware # -nfs -nfs-utils -iscsi-initiator-utils -bind -sendmail -fuse -xorg-x11-drivers -xorg-x11-server-Xorg %end %post /usr/bin/yum -y update %end Policy file allowing users in group wheel using libvirt services By adding the following policykit rule we can avoid being prompted for credentials every time we do a vagrant up or vagrant ssh : [ /etc/polkit-1/rules.d/49-vagrant.rules ] polkit.addRule ( function ( action, subject ) { if ( action.id == \"org.libvirt.unix.manage\" && subject.isInGroup ( \"wheel\" )) { return polkit.Result.YES ; } }) ;","title":"A primer on DevOps agile tools - packer","tags":"misc","loc":"http://fernandezcuesta.github.io/a-primer-on-devops-agile-tools-packer.html","url":"http://fernandezcuesta.github.io/a-primer-on-devops-agile-tools-packer.html"},{"text":"The idea is to set up a container where we can put private/secret files. A way to achieve this is setting up LUKS on top of a fix-length file, i.e. ~/Dropbox/private.img . Initialization: Initialize a (for example) 100MB file: $ dd if = /dev/urandom of = /tmp/private.img bs = 1M count = 100 Give format to the container while setting a passphrase: $ cryptsetup luksFormat /tmp/private.img $ sudo cryptsetup open /tmp/private.img private $ sudo mkfs.ext4 -L Private /dev/mapper/private Mount and copy files to it $ mkdir /tmp/private $ sudo mount /dev/mapper/private /tmp/private $ sudo chown -R ` whoami ` /tmp/priv $ cp ~/my_private_files/* /tmp/private Dismount and move the container to its final location: $ sudo umount /tmp/private $ sudo cryptsetup luksClose private $ mv /tmp/private.img ~/Dropbox/private.img Configuration: For this to be shown as a device, we can do the following: Option 1: using /etc/rc.local systemd compatibility 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash IMG_LOCATION = /home/user/Dropbox/private.img case $1 in start ) # start script losetup --find --show $IMG_LOCATION ;; stop ) # stop script losetup -d ` losetup | grep -Po \".+(?=(\\s+\\d){4}.* $IMG_LOCATION )\" ` ;; esac exit To start this on every boot do: $ sudo chmod +x /etc/rc.local And ensure the unit file for rc.local compatibility ( /etc/systemd/system/rc-local.service ) is enabled and contains: [ Unit ] Description = /etc/rc.local Compatibility ConditionPathExists = /etc/rc.local [ Service ] Type = forking ExecStart = /etc/rc.local start ExecStop = /etc/rc.local stop TimeoutSec = 0 StandardOutput = tty RemainAfterExit = yes SysVStartPriority = 99 [ Install ] WantedBy = multi-user.target Option 2: systemd unit Create a systemd user unit file as follows under /etc/systemd/system , for example /etc/systemd/system/mountloop.service : [ Unit ] Description = Mount loop device DefaultDependencies = no Conflicts = umount.target After = local-fs.target [ Service ] Type = forking Environment = \"IMG_LOCATION=/home/user/Dropbox/private.img\" ExecStart = /usr/sbin/losetup --find --show ${ IMG_LOCATION } ExecStop = /bin/bash -c \"/usr/sbin/losetup -d `losetup | grep -Po \\\".+(?=(\\s+\\d){4}.* ${ IMG_LOCATION } )\\\"`\" TimeoutSec = 0 RemainAfterExit = yes [ Install ] WantedBy = default.target Then enable this unit file: $ sudo systemctl daemon-reload $ sudo systemctl enable mountloop $ sudo systemctl start mountloop","title":"Encrypted filesystem in Dropbox","tags":"misc","loc":"http://fernandezcuesta.github.io/encrypted-filesystem-in-dropbox.html","url":"http://fernandezcuesta.github.io/encrypted-filesystem-in-dropbox.html"},{"text":"Using virtualenv while working on python projects helps in many ways: Minimizes the risk of bad dependencies between different projects under development in the same machine Minimizes the risk of bad dependencies amongst members of the same team Allows a fast and easy sandbox for testing small chunks of code, new libraries, etc without affecting other projects Allows working with different python versions (major and minor) A convenient way to set it up is using virtualenvwrapper (assuming everything's in place and shell startup file was sourced and WORKON_HOME is set to /data/venv ): $ mkvirtualenv test_project (test_project) /data/venv/test_project $ pip install django (test_project) /data/venv/test_project $ python --version Python 3.5.0 (test_project) /data/venv/test_project $ deactivate # Create a python2 virtualenv /data/venv/test_project $ cd ~ $ mkvirtualenv tests_py2 --python=`which python2` # populate the third party libraries from a requirements file (tests_py2) /data/venv/tests_py2 $ cd /devel (tests_py2) /devel $ pip install -r requirements.txt (tests_py2) /devel $ cd #go back to the virtualenv's home folder (tests_py2) /data/venv/tests_py2 $ python --version Python 2.7.10 If using ipython as the interactive python interpreter, we can set a postactivate hook in $WORKON_HOME to load the correct version of ipython : #!/usr/bin/zsh # This hook is sourced after every virtualenv is activated. cd () { if (( $# == 0 )) then builtin cd $VIRTUAL_ENV / $( basename $VIRTUAL_ENV ) else builtin cd \" $@ \" fi } cd if [[ $( python --version 2> & 1 ) = ~ \" $* \\s2\\.*\" ]] ; then alias ipython = /usr/bin/ipython2 ; else alias ipython = /usr/bin/ipython3 ; fi Plus the next snippet for running ipython inside virtual environments (under ~/.ipython/profile_default/startup/ , for example 50-run-inside-venv.py ) as explained here : from __future__ import print_function import site import sys from os import environ from os.path import join if 'VIRTUAL_ENV' in environ : virtual_env = join ( environ . get ( 'VIRTUAL_ENV' ), 'lib' , 'python %d . %d ' % sys . version_info [: 2 ], 'site-packages' ) # Remember original sys.path. prev_sys_path = list ( sys . path ) site . addsitedir ( virtual_env ) # Reorder sys.path so new directories at the front. new_sys_path = [] for item in list ( sys . path ): if item not in prev_sys_path : new_sys_path . append ( item ) sys . path . remove ( item ) sys . path [ 1 : 1 ] = new_sys_path print ( 'virtualenv->' , virtual_env ) del virtual_env del site , environ , join , sys Update If we have the powerline extension for ipython , we can invoke it directly before entering the virtualenv. With the scenario described above this is as ease as adding these lines to ipython's configuration file ~/.ipython/profile_default/ipython_config.py : if not hasattr ( sys , 'real_prefix' ): # Running outside a virtualenv c . InteractiveShellApp . extensions = [ 'powerline.bindings.ipython.post_0_11' ] In case we decide to install ipython inside the virtualenv, the previous code will skip not use the powerline extension while within the virtualenv. This is usually the right thing because otherwise we should install `powerline-status in all our virtual environments. Update ( II ) If using ST3 as text editor it may be convenient to add the following hook to postmkvirtualenv : #!/usr/bin/zsh # This hook is sourced after a new virtualenv is activated. proj_name = $( basename $VIRTUAL_ENV ) sed 's\\$VIRTUAL_ENV\\' $VIRTUAL_ENV '\\g' $WORKON_HOME /skeleton.sublime-project >> $VIRTUAL_ENV / $proj_name .sublime-project add2virtualenv $VIRTUAL_ENV / $proj_name so the template file ( skeleton.sublime-project , see below) is copied with the appropriate name inside the newly created virtual environment. { \"build_systems\" : [ { \"file_regex\" : \"&#94;[ ]*File \\\"(...*?)\\\", line ([0-9]*)\" , \"name\" : \"Anaconda Python Builder\" , \"selector\" : \"source.python\" , \"shell_cmd\" : \"$VIRTUAL_ENV/bin/python -u \\\"$file\\\"\" } ], \"folders\" : [ { \"follow_symlinks\" : true , \"path\" : \".\" } ], \"settings\" : { \"python_interpreter\" : \"$VIRTUAL_ENV/bin/python\" } } For reference, other customized hook scripts: premkvirtualenv #!/usr/bin/zsh mkdir -p $WORKON_HOME / $1 / $1 postdeactivate #!/usr/bin/zsh unset -f cd cd $WORKON_HOME unalias ipython","title":"Creating python virtual environments","tags":"misc","loc":"http://fernandezcuesta.github.io/creating-python-virtual-environments.html","url":"http://fernandezcuesta.github.io/creating-python-virtual-environments.html"},{"text":"Wrapper for doing automatic backups of the system unit ( DSA0: ) in OpenVMS. In a nutshell: It assumes that OS is installed in DSA0: unit. This script is basically invoking the OpenVMS' backup command. The resulting file is always stored locally (where configured) and transferred via s/ FTP to a remote SAN . Full and incremental/daily backups can be done. Script takes care of housekeeping according to configured values. In order to safeguard against loss or corruption of relevant information of the system, or to periodically archive copies of the most important (configuration) files, a backup of the data is needed. The resulting archives may be used to recover the original information after a disaster (for example if system disk is damaged), or to restore data from an earlier time. OpenVMS provides several ways to backup files, being the embedded backup tool the most powerful and widely used. Using this tool an operator can: Make image backups of a unit (snapshots of the whole content of a disk volume). In the case of the system unit, the bootstrap data is saved in the archive. Make file based backups (archive of selected folders and files). No bootstrap data is usually saved in file based backups. Optionally a DB backup (Oracle RDB or Mimer) will be done online into a file saved in system unit (inside DSA0:[BACKUP] folder). In some systems, this DB already resides in the system unit and this step is not necessary (but may be forced). No other data is backed up. In order to speed the process up and minimize the impact on size and bandwidth needed to store and transfer the resulting archives into the data warehouse, it is recommended to keep the system unit clean. The procedure described in the following chapters defines how to make a backup of the system volume to a separate disk, and how to roll back in case of the system disk needs to be restored to a previous state. In the following examples, a full backup of the system volume to the spare SAS disk DKA200 is done, together with it an online backup of the database. NOTE : The spare disk available for the backup might be different from DKA200 as used for the examples. Please adjust according to your system's configuration. Later on, the opposite operation for restoring data from a backup archive will be described, as well as some troubleshooting guidelines on booting from a minimal OpenVMS unit (referred to as emergency boot). IMPORTANT : The backup procedures are to be executed with the same user (i.e. SYSTEM ) as specified for each command. 1. Preparations 1.1 Prepare target disk The target disk can be either one of the local SAS disks on each node or a shared disk from the SAN . If the target disk is not bootable, proceed as follows. It is also possible to use a LD device as destination. Initialize the disk and make it bootable (will delete all its contents!). Do not use any reserve word as system label (i.e. backup or any other known command). Refer to Troubleshooting chapter for further details. Destination volume must be initialized and mounted: Alpha: SYSTEM> INITIALIZE /NOHIGH/cluster=16/extension=256/header=8000 DKA200: BCK_DSK SYSTEM> MOUNT /OVERRIDE=IDENTIFICATION DKA200 SYSTEM> @SYS$SYSTEM:AXPVMS$PCSI_INSTALL_MIN Enter device name for target disk: (? for choices) DKA200 Do you want to create or validate boot options? (Yes/No) Yes Itanium: SYSTEM> INITIALIZE /NOHIGH/cluster=64/extension=256/header=8000 DKA200: BCK_DSK SYSTEM> MOUNT /OVERRIDE=IDENTIFICATION DKA200 SYSTEM> @SYS$SYSTEM:I64VMS$PCSI_INSTALL_MIN Enter device name for target disk: (? for choices) DKA200 Do you want to create or validate boot options? (Yes/No) Yes If the destination disk is labeled BCK_DSK , the script will automatically put the backup archives inside a BACKUP directory in it. This is the easiest way to proceed when working with local disks: units should have the same name from every node in the cluster, even if they are not labeled or identified the same (for example, disks located in different bay numbers will get different naming). If there is an already initialized unit in place, this same behaviour can be achieved by setting a logical name pointing to its label. This logical name definition may be added to sys$startup:sylogicals.com file. The logical must be defined on each node in the cluster . It is very important to use the translation_attribute qualifier as well as the ending ‘:' sign in the target unit. For example: SYSTEM> define /translation_attributes=conceal /system /exec BCK_DSK DAT0: Finally, copy the ZIP and UNZIP binaries to the emergency disk as follows: SYSTEM> copy /log *ZIP.EXE DKA200:[000000] Note : doublecheck that the versions of ZIP and UNZIP are supported as explained in 1.3. 1.2 System disk cleanup To speed up the overall process, it is recommended to first clean up the system disk by purging unnecessary files. As an example, purge files with extension log or tmp older than one week and look for files larger than 100000 blocks (5 MB ): SYSTEM> purge /log dsa0:[000000...]*.log,*.tmp /keep=7 SYSTEM> MC DFU search /size=minimum=10000 dsa0 You may also set some backups which don't need to be backed up with the following command: SYSTEM> set file /nobackup sys$system:pagefile.sys 1.3 Required third-party tools Verify on the system that the ZIP and UNZIP tools are installed and its versions are newer or equal than those specified below. These versions are needed to pack files > 2GB in UNIX compatible format. ZIP.EXE v3.0 or higher UNZIP.EXE v6.0 or higher To verify which version is installed: SYSTEM> zip Copyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\" ' for software license. Zip 3.0 (July 5th 2008). Usage: zip == \"$ disk:[dir]zip.exe\" SYSTEM> unzip UnZip 6.00 of 20 April 2009, by Info-ZIP. For more details see: unzip -v. Latest versions can be downloaded from ftp.info-zip.org/pub/infozip/vms/ . 1.4 Export SSH public key If it is planned to send the resulting file to a remote server using SFTP with public key authentication as transference method, the public key of the system has to be sent to the remote server. First of all, ensure that public-key authentication is allowed by the SSH client on configuration file TCPIP$SSH_DEVICE:[TCPIP$SSH.ssh2]ssh2_config. by looking for the value of AllowedAuthentications . Then identify the key that the client will use by doing: > type sys$login:[ssh2]identification. IdKey ID_DSA_2048_A If there are no IdKey entries, generate a new key pair with the following command. Bear in mind that OpenVMS' secure shell is based on SSH2 and the key format differs from OpenSSH. > ssh_keygen -P mykey > set file /protection=(S,W,G,O:RW) mykey Add the following entry to IDENFITICATION. file: [IDENTIFICATION.] IdKey mykey Finally, transfer the mykey.pub file to the remote system and add it to the authorization file. OpenVMS ( SSH2 ) > SET FILE/PROTECTION=(S:WRED,O:WRED,G:RE,W:R) mykey.pub Add the following entry to the [.ssh2]authorized. file under sys$login directory: IdKey mykey.pub Unix (OpenSSH) $ ssh-keygen -i -f mykey.pub >> ~/.ssh/authorized_keys 2. Creating the backup manually If the subscribers database ( SDB ) resides on the system disk, skip this step. Otherwise, create a Backup directory which will store the RDB backup file. SYSTEM> create /directory dsa0:[backup] 2.1 Perform a manual backup of the database You may skip this step if the subscriber database already resides in the system unit ( dsa0: ). Databases can be backed up online (without service interruption) directly from the command line as follows. In this example, it will be saved on dsa0:[backup] . For Oracle RDB : SYSTEM> RMU /backup/online db_logical_name dsa0:[backup]database_backup.rbf For Mimer DB : SYSTEM> @sbr$root:[scripts]bck_mimer_rdb dsa0:[backup]database_backup.bck 2.2 Perform a manual backup of the system unit Backups can be done directly from the command prompt as follows. In this example, dsa0 content will be backed up into dat0:[backup]fulldsa0.bck file. SYSTEM> backup /record/log/ignore=interlock/image/label=MANUAL_BCK dsa0: _SYSTEM> dat0:[backup]fulldsa0.bck /save_set Save only the most recent version of files: SYSTEM> backup /record/log/ignore=interlock/image/label=LAST_VERS - _SYSTEM> dsa0:[000000...]*.*; dat0:[backup]dsa0_lastv.bck /save_set Backup operation progress can be checked in the interactive session by pressing Ctrl-T . Additionally on newer OpenVMS versions (≥8.x) platforms, a compression filter ( zlib ) can be applied while archiving the files by adding the /data_format=compress qualifier to the command. 3. Running the backup automatically 3.1 Script configuration Configuration for the backup script is stored in BACKUP_CONFIG.DAT file, which should be placed in the same directory as the script (by default DSA0:[BACKUP] ). If not present or empty records, default values are coded in the scripts. See Appendix C for the settings file content. 3.2 Backup script > @dsa0:[backup]sys_backup [NOW] If run without parameters, it will assume that the backup will be performed next Backup_day at Backup_hour and will not resubmit itself. With the optional parameter NOW , the script will schedule itself (almost) immediately with the settings configured in the BACKUP_CONFIG.DAT file. Note : : The script is scheduled with lower priority (3) than other applications; this means the backup will process if the system is not busy with higher priority tasks. At high load, backup may take longer than expected. It is recommended to set the backup time somewhere in the interval between 02AM and 06AM , since this is typically the interval with lower load. 3.3 Scheduling the backup automatically If run with parameter: p1: Auto-submission (Yes/No) It will wait for next Backup_day at Backup_hour to run (those two parameters are customizable in the script, by default next Monday 02AM ). If p1 is set to ‘Yes', it will be resubmitted automatically every Backup_day at Backup_hour . For example: > @dsa0:[backup]SYS_BACKUP Yes Another option is to configure the desired value in the configuration file. Configuration item: RESCHEDULE (Yes,[No]) 3.4 Incremental daily backups While having a weekly backup (or any other periodicity) it is also possible to have incremental backups with shorter period, such as daily backups. If run with parameter: p2: Incremental (Yes/No) It can be specified that the backup to be performed is incremental (default: full backup). If set to do an incremental backup but no full backup was done before, then a full backup is made instead. When auto-submission is set, it will assume that a full backup will be done in a weekly basis (the day of the week when full backup is scheduled) while incremental backups are made the other days of the week. For example: Note : : the first parameter in this example was set to \"default\". In that case, it will look for a valid value in the configuration file, or set the coded default value if not present. > @dsa0:[backup]SYS_BACKUP default YES Configuration item: INCREMENTAL (Yes,[No]) 3.5 File transference method Once the backup is finished, the resulting archive can be sent to an external storage. Transference methods include FTP and SFTP , while the file can be also left as a ZIP archive to be pulled from an external system via any protocol that the host may accept (i.e. SCP , RCP , s/ FTP , …). This can be achieved by specifying a third parameter: p3: File transfer { FTP , SFTP , PULL =None} Example: > @dsa0:[backup]SYS_BACKUP default default SFTP 3.6 Customized backup location By default, script will look at drive labeled (or referred with a logical name) as BCK_DSK . However, a customized location may be specified rather than the coded one. If run with parameter: p4: Backup location (BCK_DSK:[ BACKUP ]) Then the backup will be performed in the specified directory. An example of specifying a destination folder follows: > @dsa0:[backup]SYS_BACKUP default default default DSA1:[BACKUP.DSA0BCK] 3.7 Exclude files from being backed up It is possible (but not recommended as will be explained) for the operator to discard some files that are not needed to store into a backup archive. For example, some log files or temporary installation directories may be excluded from being saved. Doing this allows smaller archive files and faster backup process. However, it is important to bear in mind some limitations when working with exclusion lists: Image backup (directly bootable once restored) is not possible. Instead, all files rather than those in the exclusion lists are copied, but boot block is not saved inside the archive. Thus, the resulting image will not be bootable once it is restored in a real disk. Overall recovery process is significantly slower and more complex due to boot block recovery (which is lost during the backup). When restoring the file-system, follow the procedures explained in \"Restore system disk from a non-image backup\" and \"Restore system disk from image backup\" depending on whether or not an exclusion list was used or not respectively. 4. Operations with backup archive files 4.1 Show files stored in a backup archive It is possible to show the list of files archived inside a backup save set. This list can be optionally redirected to a file for future usage ( FILES.LIS in the example), and details can also be expanded with /FULL qualifier. > BACKUP /LIST[=FILES.LIS] BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET [/FULL] 4.2 Extract files from a backup archive In order to extract a file of directory from the archive, a selection (filespec) and destination must be specified as follows: Restoring a single file: > BACKUP BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /SELECT=index.dat dsa0:[stats]index.dat Restoring several files: > BACKUP BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log /SELECT=[scripts]*.com dsa:[scripts] Restoring a full directory: > BACKUP BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log /SELECT=[django...] dsa0:[django...] Restore files from a specific user ( UIC ): > BACKUP BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log /BY_OWNER=[300,102] dsa0:[user2_files] 4.3 vmsbackup If the archive is residing in a Linux, Mac OS , Solaris or other Unix-like system, it is also possible to show and extract files from an archive with the vmsbackup tool. $ vmsbackup Usage: vmsbackup -{tx}[cdevwF][-b blocksize][-s setnumber][-f tapefile] Version 4.4.3 Reads and optionally unpacks OpenVMS BACKUP savesets Available switches: -b --blocksize Use specified blocksize -B --binary Extract as binary files -c --complete Retain complete filename -d --directory Create subdirectories -e --extension Extract all files -f --file Read from file -F --full Full detail in listing -s --saveset Read saveset number -t --list List files in saveset -v --verbose List files as they are processed -V --version Show program version number -w --confirm Confirm files before restoring -x --extract Extract files -? --help Display this help message Some examples of vmsbackup usage follow. $ vmsbackup -tf archive.bck # list files in an archive Save set: ARCHIVE.BCK Written by: USER UIC: [000100,000001] Date: 30-Jul-2013 20:07:53 Command: BACKUP/LOG/IGNORE=INTERLOCK DSA2:[FILES...]*.* ARCHIVE.BCK /SAVE _SET Operating system: OpenVMS I64 version V8.3 BACKUP version: V8.3-1H1 CPU ID register: 80000000 Node name: _SMXXNN:: Written on: _DSA0: Block size: 32256 Group size: 10 Buffer count: 4353 [FILES]MY_LARGE_DB.DAT;2 432346347 19-Nov-2010 18:11:13 [FILES]INFO.TXT;5 654 14-Jan-2011 11:21:04 [FILES]EDIT.EXE;1 15698 02-Feb-2013 17:54:23 $ vmsbackup -tFf archive.bck info.txt # show extended file information Save set: ARCHIVE.BCK [...] [SYSMGR]INFO.TXT;1 Size: 1/16 Created: 19-Nov-2010 18:11:13 Owner: [000001,000004] Revised: 19-Nov-2010 18:11:13 (3) File ID: (3971,1,1) Expires: 01-Jan-1970 01:00:00 Backup: 01-Jan-1970 01:00:00 Protection: (S:RWED,O:RWED,G:RE,W:RE) File Organization: Sequential File attributes: Allocation 16, Extend 0 Record format: Variable length, maximum 57 bytes Record attributes: Carriage return carriage control $ vmsbackup -dxevf archive.bck # extract all files from an archive $ vmsbackup -Bdxvf archive.bck edit.exe # extract binary (B) file from an archive 4.4 VMS Backup reader (VMSBackup) There is an alternative to the vmsbackup tool that can run also on Windows platforms as well. Refer to hoffmanlabs for further information. VMSBackup Version 1.5 Jul 31 2013 VMSBackup [FILE] [-L:listoption] [-N] [-X:extractmode] [-M:mask] [-F] [-V] [-D] [-?] FILE Backup Data Set -L Selects output list listoptions S Suppress Output B Brief Output (default) F Full Output C CSV Output -N Don't Extract File Contents -X Selects Extraction Mode extractmode S Smart/Auto Mode (default) A ASCII Mode B Binary Mode R Raw Mode -M File Extraction Mask e.g. *.*, *.bin;*, *a*.*;-1 etc. Default is *.*;0. -F Extract with full path (default off) -V Extract with version numbers in the filename (default off) -D Debug Mode (default off) -DD Enhanced Debug Mode (default off) -? Display this help 5 - Restore the system 5.1 Restoring the system unit from a non-image backup The restoration process explained here will initialize the destination volume and remove all current contents. It is assumed that the system was boot from an emergency disk (or any other method like bootable CD / DVD ), SAN disks are reachable and applications that may access the database or system files are stopped. As explained before (Exclude files from being backed up), when a list of files are excluded from the backup it is not possible to perform an image backup. Image backup saves correctly the bootblock file ( GPT . SYS ) together with the other files. However for file-based backups the boot block is lost (this limitation has been fixed in newer versions of BACKUP for OpenVMS 8.4). In consequence once a file-based backup is restored into a disk, system cannot boot directly from it. If using a non-empty value for BACKUP_EXCLUDELIST , an additional step is required for the restoration process. If restoring from a full backup archive: - Destination volume must be initialized and mounted: :::factor # Alpha: SYSTEM> INITIALIZE /NOHIGH /CLUSTER=16 /EXTENSION=256 DSA0: AXPVMSSYS # Itanium: SYSTEM> INITIALIZE /NOHIGH /CLUSTER=64 /EXTENSION=256 DSA0: IA64VMSSYS SYSTEM> MOUNT /OVER=ID DSA0: Dump the backup contents to the destination volume as follows: SYSTEM> BACKUP BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log dsa0:[000000...] /exclude=(gpt.sys,indexf.sys) Estimated completion time can be shown while pressing Ctrl-T any time during extraction. Saveset volume:1, saveset block:21736 (32256 byte blocks) 480.53MB decompressed out of 26.68GB, 1% completed Decompress rate: 4.76MB/sec, estimated completion time: 18:24:39.52 If restoring from an incremental backup , a restore from a full backup must be performed first, then the incremental backup(s) as follows: Dismount and remount the volume: SYSTEM> DISMOUNT DSA0: SYSTEM> MOUNT /over=ID DSA0: Dump the incremental backups one by one: SYSTEM> BACKUP /INCREMENTAL BCK_DSK:[BACKUP]DELTA_18_JAN.SAV /SAVE_SET DSA0: SYSTEM> BACKUP /INCREMENTAL BCK_DSK:[BACKUP]DELTA_25_JAN.SAV /SAVE_SET DSA0: [...] In order to restore the boot block , run the following command: Alpha systems SYSTEM> RUN SYS$SYSTEM:WRITEBOOT Update VAX portion of boot block (default is Y): N Update Alpha portion of boot block (default is Y): Y Enter Alpha boot file: dsa0:[VMS$COMMON.SYSEXE]APB.EXE Check if dsa0:[VMS$COMMON.SYSEXE]APB.EXE is contiguous by checking the map area as follows: SYSTEM> DUMP/HEADER/BLOCK=END=0 dsa0:[VMS$COMMON.SYSEXE]APB.EXE [...] Map area Retrieval pointers Count: 1152 LBN: 8254864 If more than 1 retrieval pointer is shown, make the file contiguous as follows: SYSTEM> COPY /CONTIGUOUS dsa0:[VMS$COMMON.SYSEXE]APB.EXE.0 dsa0:[VMS$COMMON.SYSEXE]APB.EXE SYSTEM> SET FILE dsa0:[VMS$COMMON.SYSEXE]APB.EXE /NOMOVE Itanium systems This is usually not needed, since the INITIALIZE command will properly create the bootstrap on GPT.SYS file (which has 2 extends, one starting in sector 0 and the other in the last part of the unit; this may be checked with the DUMP /HEADER/BLOCK=END=0 command). SYSTEM> SET BOOTBLOCK /PRESERVE=SIGNATURE /I64 DSA0: Check consistency of the system disk : > mc dfu verify DSA0: /directory_scan /lock /fix /rebuild or > analyze /disk_structure /repair Finally restore the EFI entries as explained in 6.2/6.3 chapters. 5.2 Restoring the system unit from an image backup Restore full image to disk will initialize the destination volume and remove all current contents. It is assumed that the system was booted from an emergency disk (or any other method like bootable CD / DVD ), SAN disks are reachable processes accessing either the database or system files are stopped. If restoring from a full image : Destination volume must be mounted foreign: SYSTEM> DISMOUNT /SYSTEM DSA0: SYSTEM> MOUNT /FOREIGN DSA0: Dump the image contents to the destination volume as follows: SYSTEM> BACKUP /IMAGE BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log dsa0: Estimated completion time can be shown while pressing Ctrl-T any time during extraction. Saveset volume:1, saveset block:21736 (32256 byte blocks) 480.53MB decompressed out of 26.68GB, 1% completed Decompress rate: 4.76MB/sec, estimated completion time: 18:24:39.52 If restoring from an incremental image , a restore from a full image must be performed first, then the incremental backup(s): Destination volume must be mounted foreign: SYSTEM> DISMOUNT DSA0: SYSTEM> MOUNT /FOREIGN DSA0: Dump the image contents to the destination volume as follows: SYSTEM> BACKUP /IMAGE BCK_DSK:[BACKUP]SYSIMAGE.BCK /SAVE_SET /log dsa0: Dismount and remount the volume: SYSTEM> DISMOUNT DSA0: SYSTEM> MOUNT /over=ID DSA0: Dump the incremental backups one by one: SYSTEM> BACKUP /INCREMENTAL BCK_DSK:[BACKUP]DELTA_18_JAN.SAV /SAVE_SET DSA0: SYSTEM> BACKUP /INCREMENTAL BCK_DSK:[BACKUP]DELTA_25_JAN.SAV /SAVE_SET DSA0: [...] Check consistency of the system disk : > mc dfu verify DSA0: /directory_scan /lock /fix /rebuild or > analyze /disk_structure /repair Finally restore the EFI entries as explained in 6.2/6.3 chapters. 5.3 Restoring the Database 5.3.1. Stop attached processes In order to restore the Database ( SDB ), it is needed that no users are attached to it. To check if there is any other process attached to the SDB , run the following commands: Oracle: SYSTEM> RMU/DUMP/USER db_sdb (should report: \"NO ACTIVE USERS\" ) Mimer: SYSTEM> mc sysman set environment /cluster SYSMAN> DO MIMCONTROL /STATUS %SYSMAN-I-OUTPUT, command execution on node SYSTEM_1 The server for database DB_SDB is Running New logins are Enabled Directory for SYSDB is SYSTEM_DB:[DB_SDB] Number of connections to server: 2 [...] SYSMAN> DO MIMCONTROL /STOP DB_SDB SYSMAN> exit 5.3.2. Restore SDB from a backup Oracle: SYSTEM> RMU /RESTORE /NOCDD /LOG /NEW_VERSION - _SYSTEM> /DIR=DATABASE_DISK:[DATA] database_backup.rbf Mimer: SYSTEM> @sbr$root:[scripts]RCV_MIMER_RDB database_backup.bck At this stage, services that make use of the database may be started back. 6 - Troubleshooting 6.1 Emergency disk initialization This method installs a minimum OpenVMS Environment (install with no options) on a disk from which backup and restore operations can be performed for the system unit. The minimum OpenVMS Environment is created in the [SYSE] root on the disk, which runs a subset of OpenVMS and is indicated by the triple dollar sign ( $$$ ) system prompt. For the examples below, assume that disk DKA200: will be initialized with minimum OpenVMS Environment ( emergency boot disk). The target disk must be mounted privately to your process (this prevents other users from accessing this disk during the installation and backup procedures). Therefore, if the target disk was mounted with the /SYSTEM , /CLUSTER , /GROUP , or /SHARE qualifier, dismount that disk and mount it without those qualifiers or the /FOREIGN qualifier. For example: SYSTEM> INITIALIZE /NOHIGH/cluster=64/extension=256/header=8000 DKA200: BCK_DSK SYSTEM> MOUNT/OVERRIDE=IDENTIFICATION DKA200: For OpenVMS I64, enter the following command (answer YES when asked to create the boot option): SYSTEM> @SYS$SYSTEM:I64VMS$PCSI_INSTALL_MIN.COM DKA200: For OpenVMS Alpha, enter the following command: SYSTEM> @SYS$SYSTEM:AXPVMS$PCSI_INSTALL_MIN.COM DKA200: Refer to 1.1 for more information about the output of these commands. Finally, copy the ZIP and UNZIP binaries to the emergency disk. Note : : doublecheck that the versions of ZIP and UNZIP are supported as explained in 1.3. 6.2 Restoring EFI entries (Itanium) Once a system unit has been restored from a backup, EFI entries may not be correct and need to be fixed. Otherwise, automatic boot process will fail since the default entry has an incorrect value. In order to fix this, the following process must be followed: SYSTEM> @SYS$MANAGER:BOOT_OPTIONS OpenVMS I64 Boot Manager Boot Options List Management Utility (1) ADD an entry to the Boot Options list (2) DISPLAY the Boot Options list (3) REMOVE an entry from the Boot Options list (4) MOVE the position of an entry in the Boot Options list (5) VALIDATE boot options and fix them as necessary (6) Modify Boot Options TIMEOUT setting (B) Set to operate on the Boot Device Options list (D) Set to operate on the Dump Device Options list (G) Set to operate on the Debug Device Options list (E) EXIT from Boot Manager utility You can also enter Ctrl-Y at any time to abort this utility. Enter your choice: 5 To validate all entries in the Boot Options list, press Return. To validate specific entries, enter the entry number or device name. (Enter \"?\" to display Boot Options list): <RETURN> Do you really want to validate all list entries? (Yes/No) Yes Enter your choice: E 6.3 Restoring boot entries (Alpha) On Alpha platforms, once the system unit has been restored from a backup, boot entries may not be correct and need to be fixed. The following lines show an example of restoring the default boot entries on an Alpha system from the chevron prompt ( >>> ). P00>>> init Initializing... [...] P00>>> show device dga100.1001.0.8.1 $1$DGA100 HSG80 V87F Fibre disks dga104.1001.0.8.1 $1$DGA104 HSG80 V87F dgb100.1003.0.8.0 $1$DGA100 HSG80 V87F dgb104.1003.0.8.0 $1$DGA104 HSG80 V87F dkb400.4.0.106.0 DKB400 COMPAQ BD009635CB BDC4 SAS disks dkb500.5.0.106.0 DKB500 COMPAQ BD009635CB BDC4 dqa0.0.0.105.0 DQA0 CD-224E 9.5B 3.5'' drive dva0.0.0.0.0 DVA0 CD/DVD drive eia0.0.0.2005.1 EIA0 00-06-2B-00-C7-E6 Ethernet devices eib0.0.0.3004.1 EIB0 00-08-02-61-91-62 eic0.0.0.3005.1 EIC0 00-08-02-61-91-63 eid0.0.0.2004.0 EID0 00-08-02-61-91-80 eie0.0.0.2005.0 EIE0 00-08-02-61-91-81 pga0.0.0.8.1 PGA0 WWN 1000-0000-c92c-c5f1 Fibre channels pgb0.0.0.8.0 PGB0 WWN 1000-0000-c92c-d63d pka0.7.0.6.0 PKA0 SCSI Bus ID 7 SCSI channels pkb0.7.0.106.0 PKB0 SCSI Bus ID 7 P00>>> wwidmgr -clear all P00>>> wwidmgr -quickset -udid 100 Disk assignment and reachability after next initialization: 6000-1fe1-001b-bee0-0009-2310-0258-0047 via adapter: via fc nport: connected: dga100.1001.0.8.1 pga0.0.0.8.1 5000-1fe1-001b-bee1 No dga100.1002.0.8.1 pga0.0.0.8.1 5000-1fe1-001b-bee4 Yes dgb100.1003.0.8.0 pgb0.0.0.8.0 5000-1fe1-001b-bee2 No dgb100.1004.0.8.0 pgb0.0.0.8.0 5000-1fe1-001b-bee3 Yes P00>>> wwidmgr -quickset -udid 104 Disk assignment and reachability after next initialization: 6000-1fe1-001b-bee0-0009-2300-0170-001f via adapter: via fc nport: connected: dga104.1001.0.8.1 pga0.0.0.8.1 5000-1fe1-001b-bee1 No dga104.1002.0.8.1 pga0.0.0.8.1 5000-1fe1-001b-bee4 Yes dgb104.1003.0.8.0 pgb0.0.0.8.0 5000-1fe1-001b-bee2 No dgb104.1004.0.8.0 pgb0.0.0.8.0 5000-1fe1-001b-bee3 Yes P00>>> set mode diag P00>>> init P00>>> show device [...output omitted...] P00>>> show bootdef_dev bootdef_dev dga100.1002.0.8.1 P00>>> set bootdef_dev dga100.1002.0.8.1, dgb100.1004.0.8.0, dga100.1001.0.8.1, dgb100.1003.0.8.0, dga104.1002.0.8.1, dgb104.1004.0.8.0, dga104.1001.0.8.1, dgb104.1003.0.8.0 The system will follow this order (boot from 1st bootstrap available). P00>>> boot 6.4 Add an EFI entry for the emergency disk (Itanium) When present, the EFI entry for booting from an emergency disk may be useful for the operator. Using the same menu-driven application as explained above, add an entry for an emergency disk (i.e. DKA200: ) installed in the current node. This unit must be mounted before running the script. Choose option (1) from the menu, then check with option (2). SYSTEM> @SYS$MANAGER:BOOT_OPTIONS OpenVMS I64 Boot Manager Boot Options List Management Utility (1) ADD an entry to the Boot Options list (2) DISPLAY the Boot Options list (3) REMOVE an entry from the Boot Options list (4) MOVE the position of an entry in the Boot Options list (5) VALIDATE boot options and fix them as necessary (6) Modify Boot Options TIMEOUT setting (B) Set to operate on the Boot Device Options list (D) Set to operate on the Dump Device Options list (G) Set to operate on the Debug Device Options list (E) EXIT from Boot Manager utility You can also enter Ctrl-Y at any time to abort this utility. Enter your choice: 1 Enter the device name (Enter \"?\" for a list of devices): $1$DKA200: Would you like to mount $1$DKA200: ? (Yes/No) [YES] Enter the desired position number (1,2,3,,,) of the entry. To display the Boot Options list, enter \"?\" and press Return. Position [1]: 3 Enter the value for VMS_FLAGS in the form n,n. VMS_FLAGS [NONE]: e,0 Enter a short description (do not include quotation marks). Description [\"$1$DKA200:\"]: EMERGENCY efi$bcfg: $1$dka200: (Boot0005) Option successfully added Enter your choice: 2 To display all entries in the Boot Options list, press Return. To display specific entries, enter the entry number or device name. (Enter \"?\" for a list of devices): <RETURN> EFI Boot Options list: Timeout = 10 secs. Entry Description Options ----- ---------------------------------------------------------- ------------- 1 OpenVMS IA64 PKC0.5000-C500-2396-AD49 -fl 0,0 $3$DGA10 PCI(0|7|0|0) Sas(5000C5002396AD49,Lun0) 2 EFI Shell [Built-in] VenHw(d65a6b8c-71e5-4df0-d2f009a9) 3 EMERGENCY PKA0.5000-C500-240F-5681 -fl e,0 $1$DKA200 PCI(0|1|1|0) Sas(5000C500240F5681,Lun0) 4 Internal Bootable DVD -fl 0,0 $1$DNA0 PCI(0|0|2|2) Usb(1,0) -------------------------------------------------------------------------------- 5 entries found. 6.5 Manually booting from an emergency disk Use the emergency system disk (on which the minimum OpenVMS environment was installed) to perform backup and restore operations as follows: Alpha Halt the node, then from the chevron prompt: > >> BOOT -FLAGS E,0 DKA200 IA64 Reboot the node, then enter to the EFI shell once the boot entries menu is displayed. Identify which is the emergency disk from the detected devices, then run the vms loader with flags e,0 (emergency root, no cluster). Local disks are tagged as SAS (Serial Attached SCSI ) while units mounted from a disk controller appear as Fibre or SCSI . Shell> reconnect -r Shell> map -r -fs Shell> vms_show device -fs VMS: DKA0 COMPAQ BF1468B26B HPB9 V8_3 EFI: fs0: Acpi(HWP0002,300,PNP0A03)/Pci(1|0)/Scsi(Pun0,Lun0)fs VMS: DKC-1 HP DG072BB975 HPDC V8_3 EFI: fs2: Acpi(HWP0002,400,PNP0A03)/Pci(1|0)/Sas(Addr5000C5000B9E4625) VMS: DKD0 COMPAQ BF1468B26B HPB9 V8_3 EFI: fs4: Acpi(HWP0002,700,PNP0A03)/Pci(1|0)/Scsi(Pun0,Lun0) Shell> fs2:\\efi\\vms\\vms_loader.efi -flags e,0 Refer to \"OpenVMS upgrade and installation Manual, Appendix B.3: Overview of Using EFI \" for more information on how to access the EFI shell. 6.6 Backup archive attributes During backup archive transference, file attributes may be modified, especially when working with different Operative Systems (like push the backup to a UNIX server). When FTP is used for the transference, backup and recovery of the attributes can be achieved when setting /FDL qualifier in OpenVMS client. For SFTP , it is suggested to either archive the .BCK file into a ZIP file with \"-V\" flag set or use the FDL (File Definition Language) file to manually restore the original RMS properties of the backup archive. For the former, the RMS file attributes are stored in the zipped archive, and can be retained while deflating with unzip \"-V\", thus FDL file is not needed. Manual restoration may also be needed when not working with the script (i.e. transferring the file manually). For restoring file attributes of the backup images do: SYSTEM> CONVERT /FDL=backup_archive.fdl transferred_backup.bck recovered_backup.bck If the backup file is damaged, there are some other ways to recover its contents: SYSTEM> BACKUP /list /save_set /repair backup_archive.bck Else try: SYSTEM> @RESET_BACKUP_SAVESET_ATTRIBUTES.COM backup_archive.bck Refer to Appendix B for RESET_BACKUP_SAVESET_ATTRIBUTES.COM content. In various cases the following commands might work: SYSTEM> SET FILE/ATTRIBUTES=(RFM:FIX,MRS:32256,LRL:32256,RAT:NONE) SYSIMAGE.BCK SYSTEM> SET FILE/ATTRIBUTES=(DEQ:0,RFM:VAR,MRS:32256,LRL:32256,RAT:NONE) SYSIMAGE.BCK For restoring file attributes of RDB backup do: SYSTEM> SET FILE/ATTRIB=(DEQ:2048,RFM:FIX,MRS:32256,RAT:NONE) *.rbf Refer to the \"Guide to OpenVMS File Applications\" for more information about FDL . Besides this, the ZIP archive contains the backup operation command that was executed in the system as a comment. The archive comment can be displayed with unzip -z . Appendix A - Script workflow Appendix B - Reset backup saveset attributes script DCL script useful for resetting saveset file attributes. $! RESET_BACKUP_SAVESET_ATTRIBUTES.COM $! $! P1 is the specification of the BACKUP saveset $! $! This procedure resets the record format and record $! length attributes of a BACKUP saveset -- savesets $! can get \"broken\" during certain sorts of file $! transfers -- such as FTP. This procedure reads the $! (undocumented) saveset record attributes directly $! out of the target file. $! $! First render the saveset readable, and implicitly $! check that the file exists. $! $ Set File - /Attributes=(RFM:FIX,MRS:512,LRL=512,ORG=SEQ,RAT=NONE) - 'p1' $ $ Open/Error=whoops/Read BckSaveset 'p1' $ Read/Error=whoops/End=whoops BckSaveset Record $ Close/Nolog BckSaveset $ $! Find the blocksize from within the record... $ $ BlockSize = 0 $ BBH_L_BLOCKSIZE = %x28*8 $ BlockSize = F$CVUI(BBH_L_BLOCKSIZE, 32, Record) $ If BlockSize .lt. 2048 .or. BlockSize .gt. 65535 $ Then $ Write sys$output \"Unexpected block size\" $ Goto whoops $ Else $ Set File /Attributes=(RFM:FIX,LRL='BlockSize', - MRS='BlockSize',RAT=none) - 'p1' $ endif $ exit $WHOOPS: $ Write sys$output \"Error\" $ exit Appendix C - Script configuration file Script configuration file example. [SYS_BACKUP_CFG] # Configuration item: BACKUP_DIRECTORY. Format: Directory. BACKUP_LOCATION = \"bck_dsk:[backup]\" # Configuration item: BACKUP_EXCLUDELIST. Format: Filespec (Comma sep.) # Directories must be specified as [DIRECTORY.NAME...]* # If BACKUP_EXCLUDELIST is empty, Image backup will be performed BACKUP_EXCLUDELIST = \"*.LOG,[GOLD.KITS...]*,*.PCSI*,*.ZIPEXE\" # Configuration item: BACKUP_TIME # Format: \"hh:mm\" time for the reschedule BACKUP_TIME = \"02:00\" # Configuration item: BACKUP_WDAY - day of the week for full backup # Format: {Monday,Tuesday,Wednesday,Thursday,Friday,Saturday,Sunday} BACKUP_WDAY = \"Monday\" # Configuration item: INCREMENTAL (Yes,[No]) # Incremental backups are done daily, # otherwise weekly at Backup_wday:Backup_time INCREMENTAL = \"NO\" # Configuration item: RESCHEDULE (Yes,[No]) RESCHEDULE = \"YES\" # Configuration item: SDB_FORCE (Yes,[No]) SDB_FORCE = \"YES\" # Database name: SDB_NAME #SDB_NAME = \"\" # Configuration item: SDB_KEEPDAYS-> SDB backups local store days ([30]) SDB_KEEPDAYS = 30 # Configuration item: BACKUP_DAYS_KEEP_LOCAL_ARCHIVE # Format: Integer BACKUP_DAYS_KEEP_LOCAL_ARCHIVE = \"30\" # Configuration item: ZIP_ARCHIVE (\"Always\",[\"Skip\"]) ZIP_ARCHIVE = \"SKIP\" # # Configuration item: BACKUP_LOG_DIR BACKUP_LOG_DIR = \"bck_dsk:[BACKUP.LOG]\" # Configuration item: FILE_TRANSFER {FTP, SFTP, PULL=None} # SFTP assumes Public-key authentication # Pull does not transfer the archive, just puts it into a ZIP file FILE_TRANSFER = \"SFTP\" [SYS_BACKUP_TX] # Transference settings (for FILE_TRANSFER values rather than PULL) # # Configuration item: BACKUP_REMOTE_DIRECTORY. Format: Directory # Use \".\" for current or default directory BACKUP_REMOTE_DIRECTORY = \".\" # Configuration item: BACKUP_REM_NODE # Format: IP address (\"n.n.n.n\") or hostname BACKUP_REM_NODE = \"ftp_san\" # Configuration item: BACKUP_REM_USER # Format: \"username password\", or \"user\" for public-key authentication BACKUP_REM_USER = \"bkpusr\" # Configuration item: BACKUP_REMOTE_SYSTEM_TYPE # Remote OS system {UNIX, VMS} BACKUP_REMOTE_SYSTEM_TYPE = \"UNIX\" # Configuration item: FILE_COUNT_FOR_TRANSFER # Number of attempts to tranfer the file FILE_COUNT_FOR_TRANSFER = 3 # Configuration item: REMOTE_SFTP_COMMAND # For SFTP, set up a command to be executed once the transfer is done REMOTE_SFTP_COMMAND = \"sh cleanup.sh\"","title":"OpenVMS system disk backup","tags":"misc","loc":"http://fernandezcuesta.github.io/openvms-system-disk-backup.html","url":"http://fernandezcuesta.github.io/openvms-system-disk-backup.html"},{"text":"Select all (but one) columns of a dataframe A fast and easy way to select all columns rather than those included in a list: df = pd . DataFrame ( randn ( 8 , 4 ), columns = [ 'A' , 'B' , 'C' , 'D' ]) A B C D 0 0.630446 - 1.454207 - 0.021687 1.095301 1 0.374037 1.301607 - 1.316152 - 0.272031 2 1.102625 - 1.109953 1.058960 0.725778 3 0.619485 1.500641 - 0.370432 - 0.356188 4 0.323979 0.008434 0.616835 - 0.632381 5 - 0.721451 0.852577 1.071660 - 0.087884 6 0.440051 - 0.340789 0.602363 - 0.442707 7 - 0.890141 1.062083 0.959767 - 0.627261 df [ df . columns - [ 'B' , 'C' ]] A D 0 0.630446 1.095301 1 0.374037 - 0.272031 2 1.102625 0.725778 3 0.619485 - 0.356188 4 0.323979 - 0.632381 5 - 0.721451 - 0.087884 6 0.440051 - 0.442707 7 - 0.890141 - 0.627261 # Another (more flexible) way to do the same: df . ix [:, df . columns - [ 'B' , 'C' ]] Remove outliers (actually, clipping their values up to a maximum): For this example, let's first add some outliers to the previous df: for outlier in range ( 10 ): df [ random . choice ( df . columns )][ randint ( 0 , len ( df ))] *= 3.0 df [ 'ID' ] = [ 'system %i ' % randint ( 1 , 4 ) for i in range ( len ( df ))] df A B C D ID 0 1.891338 - 1.454207 - 0.021687 9.857711 system2 1 1.122112 1.301607 - 1.316152 - 0.272031 system3 2 1.102625 - 3.329858 1.058960 0.725778 system3 3 0.619485 4.501923 - 0.370432 - 1.068563 system3 4 0.323979 0.008434 0.616835 - 0.632381 system2 5 - 0.721451 0.852577 1.071660 - 0.087884 system3 6 0.440051 - 1.022366 1.807089 - 0.442707 system2 7 - 0.890141 3.186248 0.959767 - 0.627261 system1 For example, if we know that values must lie in the range [-2, 2] we would like to clip all entries with an absolute value >2 to exactly +/- 2.00. df [ df . columns - [ 'ID' ]] = df [ df . columns - [ 'ID' ]] . clip ( lower =- 2.0 , upper = 2.0 ) df A B C D ID 0 1.891338 - 1.454207 - 0.021687 2.000000 system2 1 1.122112 1.301607 - 1.316152 - 0.272031 system3 2 1.102625 - 2.000000 1.058960 0.725778 system3 3 0.619485 2.000000 - 0.370432 - 1.068563 system3 4 0.323979 0.008434 0.616835 - 0.632381 system2 5 - 0.721451 0.852577 1.071660 - 0.087884 system3 6 0.440051 - 1.022366 1.807089 - 0.442707 system2 7 - 0.890141 2.000000 0.959767 - 0.627261 system1i Or directly using np.where : numeric = df . columns - [ 'ID' ] df [ numeric ] = np . where ( abs ( df [ numeric ]) > 2.0 , 2.0 * sign ( df [ numeric ]), df [ numeric ])","title":"Playing with pandas","tags":"misc","loc":"http://fernandezcuesta.github.io/playing-with-pandas.html","url":"http://fernandezcuesta.github.io/playing-with-pandas.html"},{"text":"Fast and easy way to live sharing the screen, useful during upgrades where the activities are to be audited real-time. The following 2 components are in place: Wemux and tmux , where the former acts as a wrapper for tmux . OpenSSH configured in such a way that guests are directly attached to an existing wemux session (or disconnected otherwise). Wemux Assuming tmux is already configured and working in the system, we can just install wemux ( wemux-git in AUR ). For the configuration we can either run wemux config or edit /etc/wemux/wemux.conf file. This is all I needed to change from the defaults: host_list =( my_local_username ) # only my own user will be running in host mode default_client_mode = \"mirror\" # all clients are attached read-only OpenSSH Create a guest user and set OpenSSH up as follows: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/bin/bash # Ensure only public key authentication is allowed $ sudo sed -E -i.bak 's/&#94;#?(PasswordAuthentication|ChallengeResponseAuthentication).*$/\\1 no/' /etc/ssh/sshd_config # Create new guest user $ sudo useradd -m guest $ echo -e 'guestpassword\\nguestpassword' | sudo passwd guest # Create ssh key for guest $ su - guest $ mkdir .ssh $ ssh-keygen -N MY_PASSPHRASE -f ~/.ssh/guest-ssh-key $ echo -n 'command=\"wemux\",no-port-forwarding,no-x11-forwarding,no-agent-forwarding ' >> ~/.ssh/authorized_keys $ cat ~/.ssh/guest-ssh-key.pub >> ~/.ssh/authorized_keys Now share keys to the other party over a secure channel. <tl;dr> Or much easier and more secure , if the other party has a github account both steps above can be shorten by using github-auth with a simple command: gh-auth add --command = \"wemux client mirror\" --users = GITHUB_USER_ID This will add the user's keys straight to our ~/.ssh/authorized keys and force the connection matching the keys to attach as mirror clients to the existing wemux session. Removing the keys is even easier with: gh-auth remove --users = GITHUB_USER_ID UPDATE : When wemux is not an option If wemux is not an option, we can still reach the same results only by using tmux and OpenSSH. What we need from the host is to open a tmux session with a specific name, for example: tmux new-session -s shared And add an authorized key to the ~/.ssh/authorized_keys file for the user that started the tmux session, like: $ echo -n 'command=\"tmux attach-session -t session -r\"' >> ~/.ssh/authorized_keys $ cat ~/.ssh/guest-ssh-key.pub >> ~/.ssh/authorized_keys The end user will have to log in with ssh user@your-host-name:REDIRECTED_PORT -i guest-ssh-key where user is the one owning the tmux server.","title":"Mirror sharing with tmux/wemux","tags":"misc","loc":"http://fernandezcuesta.github.io/mirror-sharing-with-tmuxwemux.html","url":"http://fernandezcuesta.github.io/mirror-sharing-with-tmuxwemux.html"},{"text":"Sometimes it may happen that we need to share the connection to a remote system with another person who cannot connect directly. In order to move on, there are quite a few options. Amongst others: Using a shared tmux session while the connection is established, which requires the other person to feel comfortable with tmux. Setting up a VPN to my system. Setting up an SSH tunnel listening in our outbound interface. Setting up a couple of iptables rules. On this article I'll describe last two options . For completeness, let's summarize the components in the game: VPN session is established from my laptop, which has a private IP address behind a NAT (actually behind 2 NATs, which is not relevant). Broadband router has a dynamically assigned public IP provided by my ISP . There already exist a port range forwarded from the router straight to my laptop both for UDP and TCP . So at the end, the details (as an example) are: My public IP : 1.1.1.1 Open port to my system: 50000 Assigned IP address from the VPN tunnel: 10.200.100.5 Remote system reachable from the IPSec tunnel: 10.200.0.1 The simplest option is taking advantage of OpenSSH's ability to forward incoming connections into the SSH tunnel: $ ssh user@10.200.0.1 -L 1.1.1.1:50000:localhost:22 And let the other person connect to 1.1.1.1:50000. This works great as long as we keep our SSH session open . An alternative using iptables does not have this constrain. Having a look at iptables flowchart, we may figure out what we need to set it up by following the upper side of the chart . PACKET IN | PREROUTING--[routing]-->--FORWARD-->--POSTROUTING-->--OUT - nat (dst) | - filter - nat (src) | | | | INPUT OUTPUT - filter - nat (dst) | - filter | | `----->-----[app]----->------' PREROUTING rule on NAT table to translate incoming connections on port 50000 to the remote system port 22 ( SSH ). $ iptables -t nat -A PREROUTING -p tcp --dport 50000 -j DNAT --to \\ > 10.200.0.1:22 -m comment --comment 'Redirect in 50000 to 10.200.0.1:22' FORWARD rule to allow this traffic flow between interfaces ( eth0 and tun0 ). $ iptables -I FORWARD -p tcp --dst 10.200.0.1 --dport 22 -j ACCEPT $ iptables -I FORWARD -p tcp --src 10.200.0.1 --sport 22 -j ACCEPT This also needs the kernel to allow IP forwarding, so we must check: $ if [ $( cat /proc/sys/net/ipv4/ip_forward ) = 0 ] ; then \\ > sudo sysctl -w net.ipv4.ip_forward = 1 ; fi POSTROUTING rule on NAT table to masquerade the source address of outgoing traffic. $ iptables -t nat -A POSTROUTING -d 10.200.0.1 -p tcp --dport 22 \\ > -j SNAT --to-source 10.200.100.5 With these rules in place the other person can simply access the remote system with: $ ssh username@1.1.1.1 -p 50000 The overall process can be automated with a bash script like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 #!/bin/bash GW_PORT = 22 # default gateway port GW_IP = 127.0.0.1 # default gateway ip address FWD_PORT = 8000 # default forwarding port, must be reachable from remote COMMENT = \"Added by vpn_fwd\" # comment added to iptables rules disable = false # unless specified, default action is to enable the forwarding usage () { read -d '' help <<- EOF Usage: vpn_fwd gw-ip gateway ip (defaults to $GW_IP) [--gw-port] gateway port (defaults to $GW_PORT) [--fwd-port] forwarding port (defaults to $FWD_PORT) [--iface] VPN interface name (default, first PPP interface found) vpn_fwd disable disable port forwarding to VPN Example: vpn_fwd 10.10.10.1 # redirects port 8000 to 10.10.10.1:22 vpn_fwd my_gw_host --fwd-port 44000 --iface tun2 EOF echo \" $help \" } guess_ip (){ # Look for the VPN assigned IP address (first PPP interface if nothing given) if [ -z \" $VPN_IF \" ] ; then VPN_IF = $( ifconfig | grep -Pom1 '.*(?=:\\sflags=\\d+<[\\w,]*POINTOPOINT)' ) fi if [ \" $VPN_IF \" ] ; then ifconfig $VPN_IF | grep -Po \\ '\\s*inet\\s+\\K\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b(?=\\s+netmask.*)' fi } enable_fwd () { # Enable IP forwarding if not already if [ $( cat /proc/sys/net/ipv4/ip_forward ) = 0 ] ; then sudo sysctl -w net.ipv4.ip_forward = 1 fi if [ \" $GW_IP \" == \"127.0.0.1\" ] ; then VPN_IP = $GW_IP else VPN_IP = $( guess_ip ) fi if [ \" $VPN_IP \" ] ; then # Set up iptables rules sudo iptables -t nat -A PREROUTING -p tcp --dport $FWD_PORT -j DNAT --to \\ $GW_IP : $GW_PORT -m comment --comment \" ${ COMMENT } \" sudo iptables -I FORWARD -p tcp --dst $GW_IP --dport $GW_PORT -j ACCEPT \\ -m comment --comment \" ${ COMMENT } \" sudo iptables -I FORWARD -p tcp --src $GW_IP --sport $GW_PORT -j ACCEPT \\ -m comment --comment \" ${ COMMENT } \" sudo iptables -t nat -A POSTROUTING -d $GW_IP -p tcp --dport $GW_PORT \\ -j SNAT --to-source $VPN_IP -m comment --comment \" ${ COMMENT } \" else ifconfig -a echo 'No POINTOPOINT interface was found up...' fi } disable_fwd () { # Delete all iptables rules with $COMMENT sudo sh -c 'iptables-save | grep -v \"${COMMENT}\" | iptables-restore' echo 'Forwarding disabled' sudo iptables-save | grep \" ${ COMMENT } \" } main () { if [[ ${ 1 } == \"disable\" ]] ; then disable = true return 1 else GW_IP = $( dig +short ${ 1 } ) #mandatory as first argument shift fi while [[ ${ 1 } ]] ; do case \" ${ 1 } \" in --gw-port ) GW_PORT = ${ 2 } shift ;; --fwd-port ) FWD_PORT = ${ 2 } shift ;; --iface ) VPN_IF = ${ 2 } shift ;; * ) echo \"Unknown parameter: ${ 1 } \" > & 2 usage return 1 esac if ! shift ; then echo 'Missing parameter argument.' > & 2 usage return 1 fi done } if [ -z \" $1 \" ] ; then usage else main \" ${ @ } \" if $disable ; then disable_fwd ; else enable_fwd ; fi fi","title":"Sharing a VPN session","tags":"misc","loc":"http://fernandezcuesta.github.io/sharing-a-vpn-session.html","url":"http://fernandezcuesta.github.io/sharing-a-vpn-session.html"},{"text":"Although still touching bases with pandas I came across a problem whose answer was not found after skimming through Wes McKinney's \"Python for Data Analysis\" book. Long story short, starting with a bunch of CSV files transferred from a remote system, a series of dataframes are produced one corresponding to each file. These CSVs may contain hetereogeneous information from different components, not necessarily for the very same period. As an example, let's assume the index being the sample indicator. For simplicity all the tests are done with these dataframes: df_a = pd . DataFrame ({ 'sample_nr' : [ 0 , 1 , 2 , 3 ], 'val0' : [ 2 , 3 , 6 , 8 ], 'val1' : [ 1 , 2 , 4 , 3 ]}) df_a = df_a . set_index ( 'sample_nr' ) df_b = pd . DataFrame ({ 'sample_nr' : [ 10 , 11 , 12 , 13 ], 'val2' : [ 5 , 4 , 5 , 5 ], 'val3' : [ 4 , 4 , 6 , 6 ]}) df_b = df_b . set_index ( 'sample_nr' ) df_c = pd . DataFrame ({ 'sample_nr' : [ 10 , 11 , 12 , 13 ], 'val0' : [ 1 , 3 , 2 , 1 ], 'val1' : [ 0 , 2 , 3 , 4 ]}) df_c = df_c . set_index ( 'sample_nr' ) df_d = pd . DataFrame ({ 'sample_nr' : [ 0 , 1 , 2 , 3 ], 'val2' : [ 8 , 8 , 7 , 7 ], 'val3' : [ 4 , 4 , 6 , 6 ]}) df_d = df_d . set_index ( 'sample_nr' ) Which has as result: df_a : df_b : val0 val1 val2 val3 sample_nr sample_nr 0 2 1 10 5 4 1 3 2 11 4 4 2 6 4 12 5 6 3 8 3 13 5 6 df_c : df_d : val0 val1 val2 val3 sample_nr sample_nr 10 1 0 0 8 4 11 3 2 1 8 4 12 2 3 2 7 6 13 1 4 3 7 6 The result of glueing everything together is: {df_a, df_c} and {df_d, df_b} are concatenated along their axis (as the result of df_a.merge(df_c, how='outer') ). {df_a, df_d} and {df_c, df_b} are put together horizontally, as we could get by running df_a.join(df_d) . But… what if we have not a-priori clue of how each operands look like and would like to perform a \"glue all together now \" operation? <tl;dr/> At this point, I found two options: Using pd.concat function. Using pd.combine_first function. The latter was at first glance the simplest choice: df = pd . DataFrame () for _df in [ df_a , df_b , df_c , df_d ]: df = df . combine_first ( _df ) which produces the desired output: df : val0 val1 val2 val3 sample_nr 0 2 1 8 4 1 3 2 8 4 2 6 4 7 6 3 8 3 7 6 10 1 0 5 4 11 3 2 4 4 12 2 3 5 6 13 1 4 5 6 The first option was, however, my choice due to the way that input data is obtained: df = pd . concat ([ dataframize ( a_file ) for a_file in files ], axis = 0 ) Where dataframize simply takes an input CSV and returns a pd.DataFrame() object. The outcome still needs some adjustment (indices are duplicate and half of the values are empty). df : val0 val1 val2 val3 sample_nr 0 2 1 NaN NaN 1 3 2 NaN NaN 2 6 4 NaN NaN 3 8 3 NaN NaN 0 NaN NaN 8 4 1 NaN NaN 8 4 2 NaN NaN 7 6 3 NaN NaN 7 6 10 1 0 NaN NaN 11 3 2 NaN NaN 12 2 3 NaN NaN 13 1 4 NaN NaN 10 NaN NaN 5 4 11 NaN NaN 4 4 12 NaN NaN 5 6 13 NaN NaN 5 6 So at the end this was the code used: df = pd . concat ([ dataframize ( a_file ) for a_file in files ], axis = 0 ) # properly merge the columns and restore the metadata _df = _df . groupby ( _df . index ) . last () The real reason of why choosing this and not pd.combine_first … maybe in a future post.","title":"Combining pandas dataframes","tags":"misc","loc":"http://fernandezcuesta.github.io/combining-pandas-dataframes.html","url":"http://fernandezcuesta.github.io/combining-pandas-dataframes.html"},{"text":"There are situations where an operator wants to run some custom scripts on their systems. These scripts might not be fully optimized and be the root cause for bigger problems in the overall system behaviour. It is also quite common to be asked for a way to ‘restrict' the amount of log or output files that a script can generate, in a way that the main services running on the system are not affected by a lack of space. A way to manage this is by controlling the number of log or output files to be written to a specific directory. This can be done with the SET DIRECTORY /VERSION_LIMIT or even for individual files with SET FILE /VERSION_LIMIT commands. Another way to accomplish it is by defining a Logical Disk ( LD ) . LDdriver allows OpenVMS to create a logical volume that physically resides on a single file. Similar to loop devices on Linux. The size of the virtual volume can be as big as the real volume where the file is saved can store. A couple of use cases: Burn a CD with an OpenVMS directory structure. Create a LD , mount it, copy directories to virtual volume and disconnect. The container file can now be burnt to a CD . Shrink a script not to fill up a disk. Assign the working directory to a LD with a specific size. Even if the virtual volume is 100% full, the real disk will not be affected (think about a 8GB virtual disk residing on a 100GB volume). > ld help LD The logical disk utility is a system management tool available to any user for controlling logical disk usage. A Logical Disk is a file available on a Physical Disk, which acts as a real Physical Disk (the file may or may not be contiguous). The Logical Disks are available in any directory of the Physical Disk. A large disk can be divided into smaller sections, each a Logical Disk, supporting the same I/O functions as the Physical Disk. By giving the Logical Disk File a good protection level and mounting it private or with device protection, you are able to add a number of protection levels to your file system. The logical disk is controlled by the LD utility, which can be directly invoked from DCL. Format: LD [/qualifiers] [Filespec] [Device] Additional information available: Author Command_summary Driver_functions Error_messages Features HELP New_features_V5.0 New_features_V5.1 New_features_V6.0 New_features_V6.2 New_features_V6.3 New_features_V7.0 New_features_V8.0 New_features_V8.1 New_features_V8.2 Parameters Privileges_and_Quotas Restrictions Setup IO_Trace_example CONNECT CREATE DISCONNECT NOPROTECT NOWATCH SHOW TRACE NOTRACE PROTECT WATCH VERSION Example Add the startup procedures to the SYS$STARTUP:SYSTARTUP_VMS.COM $ If f $search ( \"sys $startup :ld $startup .com\" ) .nes. Then @SYS $STARTUP :LD $STARTUP Note that this will be executed during system boot. If a reboot is not possible, invoke it manually from the system prompt with @SYS$STARTUP:LD$STARTUP , then continue with the next steps Create a 100MBlock ( 40MB ) logical drive file > ld create $ 1 $ dga200 :[repository]ldisk1.dsk /size=100000 /nobackup [/contiguous] Connect > ld connect $ 1 $ dga200 : [ repository ] ldisk1 .dsk [ lda1 : ] [ / share ] % LD-I-UNIT , Allocated device is $ 1 $ LDA1 : > ld show lda1 : % LD-I-CONNECTED , Connected $ 1 $ LDA1 : to $ 1 $ dga200 : [ repository ] ldisk1 .dsk ; 1 Initialize the logical drive with /erase parameter in order to erase any potentially sensitive data on the underlying disk device. > initialize /erase lda1: ldisk1_label > mount /over=id lda1: > show dev lda1 Device Device Error Volume Free Trans Mnt Name Status Count Label Blocks Count Cnt $ 1 $ LDA1 : (MIKO) Mounted alloc 0 LDISK1 99900 1 1 > dismount lda1: > ld disconnect lda1: /log Set the logical disk to mount automatically during startup As previously done for the LD driver startup, we can add the commands for connecting and mounting the logical disks, provided that they were successfully created. This is an example of all the lines added to the end of SYS$STARTUP:SYSTARTUP_VMS.COM : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ ! $ If f $ search ( \"sys$startup:ld$startup.com\" ) .nes. Then @SYS $ STARTUP :LD $ STARTUP $ ! $ ! Optional: for Logical Magnetic tapes (LM) $ ! If f $ search ( \"sys$startup:lm$startup.com\" ) .nes. \"\" $ ! Then $ ! @SYS $ STARTUP :LM $ STARTUP $ ! Endif $ ! $ If f $ search ( \"dsa4:[000000]SCRIPT_LD.DSK\" ) .nes. \"\" $ Then $ ld connect dsa4:[000000]SCRIPT_LD.DSK lda1: /share $ mount $ 1 $ lda1 : SCRIPT_LD /system /cluster $ Endif $ ! $ If f $ search ( \"dsa4:[000000]T4$DATA.DSK\" ) .nes. \"\" $ Then $ ld connect dsa4:[000000]T4 $ DATA . DSK lda2: /share $ mount $ 1 $ lda2 : T4 $ DATA /system /cluster $ Endif $ !","title":"Logical disks in OpenVMS","tags":"misc","loc":"http://fernandezcuesta.github.io/logical-disks-in-openvms.html","url":"http://fernandezcuesta.github.io/logical-disks-in-openvms.html"},{"text":"With some VPN clients like Cisco Anyconnect, the DNS records can be automatically assigned by the VPN server during negotiation of the secure connection. This shouldn't be a problem if we have access to /etc/resolv.conf file. For example enabling the immutable flag ( chattr +i /etc/resolv.conf ) before connecting or doing a backup&restore of such file. However Anyconnect client temporarily modifies this file during initialization and monitors it, so changes are not possible without dropping the connection. Fast an easy way to do this with iptables: redirect all DNS queries (on port 53) to our preferred or local DNS server. For example: $ iptables -t nat -A OUTPUT -p udp --dport 53 -j DNAT --to 8.8.8.8:53 $ iptables -t nat -A OUTPUT -p tcp --dport 53 -j DNAT --to 8.8.8.8:53 Now, all DNS queries will be redirected to our preferred DNS , regardless of what's imposed by Cisco client on our /etc/resolv.conf file.","title":"Bypassing DNS assigned by VPN","tags":"misc","loc":"http://fernandezcuesta.github.io/bypassing-dns-assigned-by-vpn.html","url":"http://fernandezcuesta.github.io/bypassing-dns-assigned-by-vpn.html"},{"text":"And 20min later… Hello world!","title":"load \"\"","tags":"misc","loc":"http://fernandezcuesta.github.io/load.html","url":"http://fernandezcuesta.github.io/load.html"}]}